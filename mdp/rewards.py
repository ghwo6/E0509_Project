# mdp/rewards.py

# âœ… 1. ì´ ì¤„ì´ ì—†ìœ¼ë©´ Type Hint ì—ëŸ¬ê°€ ë‚©ë‹ˆë‹¤! (ê°€ì¥ ì¤‘ìš”)
from __future__ import annotations

import torch
from typing import TYPE_CHECKING

from isaaclab.managers import SceneEntityCfg
from isaaclab.assets import Articulation, RigidObject
from isaaclab.utils.math import quat_rotate, quat_from_angle_axis

# 2. ManagerBasedRLEnvëŠ” ì—¬ê¸°ì„œë§Œ ë¶ˆëŸ¬ì˜¤ì§€ë§Œ, 
# ë§¨ ìœ—ì¤„ì˜ 'annotations' ë•ë¶„ì— ì•„ë˜ í•¨ìˆ˜ ì •ì˜ì—ì„œ ì—ëŸ¬ê°€ ì•ˆ ë‚¨
if TYPE_CHECKING:
    from isaaclab.envs import ManagerBasedRLEnv

def object_ee_distance(env: ManagerBasedRLEnv, robot_cfg: SceneEntityCfg, object_cfg: SceneEntityCfg) -> torch.Tensor:
    """
    1. Sweet Spot(Z +0.105m)ì„ ê¸°ì¤€ìœ¼ë¡œ ê±°ë¦¬ë¥¼ ì°ë‹¤.
    2. Sweet Spotì˜ Zì¶•ê³¼ íœì˜ Zì¶•ì´ ì¼ì¹˜í•˜ëŠ”ì§€ ë³¸ë‹¤.
    3. (ë””ë²„ê¹…) ì²« ì‹¤í–‰ ì‹œ ë¡œë´‡ì˜ ê´€ì ˆ ê°ë„ë¥¼ ì¶œë ¥í•œë‹¤.
    """
    
    # [ë°ì´í„° ê°€ì ¸ì˜¤ê¸°]
    robot: Articulation = env.scene[robot_cfg.name]
    pen: RigidObject = env.scene[object_cfg.name]
    
    # -------------------------------------------------------------
    # ğŸ–¨ï¸ [ë””ë²„ê¹…] ì´ˆê¸° ê´€ì ˆ ê°ë„ ì¶œë ¥ (ì²« ë²ˆì§¸ í™˜ê²½, ì²« ìŠ¤í…ì—ì„œë§Œ)
    # -------------------------------------------------------------
    if env.common_step_counter == 0: 
        print("\n" + "="*50)
        print("ğŸ¤– [Robot Debug] Initial Joint Positions (Env 0)")
        # ì²« ë²ˆì§¸ ë¡œë´‡ì˜ ê´€ì ˆ ê°ë„ ê°€ì ¸ì˜¤ê¸°
        joint_pos_0 = robot.data.joint_pos[0].cpu().tolist()
        formatted_pos = [f"{x:.4f}" for x in joint_pos_0]
        print(f"   Joint Angles: {formatted_pos}")
        print("="*50 + "\n")

    # -------------------------------------------------------------
    # ğŸ¯ Sweet Spot ìœ„ì¹˜ ë° íšŒì „ ê³„ì‚°
    # -------------------------------------------------------------
    # 1. ê·¸ë¦¬í¼ ë² ì´ìŠ¤(ì†ëª©)ì˜ ìœ„ì¹˜ì™€ íšŒì „
    ee_w = robot.data.body_state_w[:, robot_cfg.body_ids[0], :3]
    ee_quat_w = robot.data.body_state_w[:, robot_cfg.body_ids[0], 3:7]
    
    # 2. ì˜¤í”„ì…‹ ì ìš© (Base -> Sweet Spot : Zì¶•ìœ¼ë¡œ 0.105m)
    offset_vec = torch.tensor([0.0, 0.0, 0.105], device=env.device).repeat(env.num_envs, 1)
    
    # íšŒì „ì„ ê³ ë ¤í•˜ì—¬ ì˜¤í”„ì…‹ì„ ë”í•¨
    sweet_spot_pos = ee_w + quat_rotate(ee_quat_w, offset_vec)

    # -------------------------------------------------------------
    # ğŸ“ ê±°ë¦¬ ë³´ìƒ (Distance Reward)
    # -------------------------------------------------------------
    pen_pos = pen.data.root_pos_w
    distance = torch.norm(pen_pos - sweet_spot_pos, dim=-1)
    rew_dist = 1.0 / (1.0 + torch.square(distance)) # ê°€ê¹Œìš¸ìˆ˜ë¡ ì ìˆ˜ í¼

    # -------------------------------------------------------------
    # ğŸ§­ ë°©í–¥ ë³´ìƒ (Orientation Reward) - Zì¶• ë§ì¶”ê¸°
    # -------------------------------------------------------------
    vec_z = torch.tensor([0.0, 0.0, 1.0], device=env.device).repeat(env.num_envs, 1)
    sweet_spot_z_dir = quat_rotate(ee_quat_w, vec_z)

    pen_quat = pen.data.root_state_w[:, 3:7]
    pen_z_dir = quat_rotate(pen_quat, vec_z)

    dot_prod = torch.sum(sweet_spot_z_dir * pen_z_dir, dim=-1)
    rew_orient = torch.clamp((dot_prod + 1.0) / 2.0, min=0.0, max=1.0)

    # [ìµœì¢… í•©ì‚°]
    total_reward = rew_dist + (rew_dist * rew_orient * 0.5)
    
    return total_reward

def pen_orientation_reward(env: ManagerBasedRLEnv, robot_cfg: SceneEntityCfg, object_cfg: SceneEntityCfg) -> torch.Tensor:
    """
    ë¡œë´‡ ì†(EE)ê³¼ íœ(Object)ì˜ íšŒì „ ê°ë„ê°€ ì¼ì¹˜í• ìˆ˜ë¡ ì ìˆ˜ë¥¼ ì¤ë‹ˆë‹¤.
    """
    robot: Articulation = env.scene[robot_cfg.name]
    pen: RigidObject = env.scene[object_cfg.name]
    
    ee_quat = robot.data.body_state_w[:, robot_cfg.body_ids[0], 3:7]
    pen_quat = pen.data.root_state_w[:, 3:7]
    
    quat_dot = torch.bmm(ee_quat.unsqueeze(1), pen_quat.unsqueeze(2)).squeeze()
    
    return torch.square(quat_dot).squeeze()